package app

import (
	"context"
	"fmt"
	"os"
	"path/filepath"
	"strings"
	"time"

	"tensorvault/pkg/exporter"
	"tensorvault/pkg/index"
	"tensorvault/pkg/meta"
	"tensorvault/pkg/refs"
	"tensorvault/pkg/storage"
	"tensorvault/pkg/storage/cache"
	"tensorvault/pkg/storage/disk"
	"tensorvault/pkg/storage/s3"

	"github.com/spf13/viper"
)

// App æ˜¯æ•´ä¸ªåº”ç”¨ç¨‹åºçš„ä¾èµ–å®¹å™¨ (Dependency Container)
type App struct {
	Store      storage.Store
	Index      *index.Index
	Refs       *refs.Manager
	RepoPath   string // æœ¬åœ°ä»“åº“æ ¹ç›®å½• (.tv)
	Repository *meta.Repository
}

// NewApp æ˜¯å·¥å‚å‡½æ•°ï¼Œè´Ÿè´£ç»„è£…ç³»ç»Ÿ
func NewApp() (*App, error) {
	var metaDB *meta.DB
	var repository *meta.Repository
	var refMgr *refs.Manager
	// åˆå§‹åŒ–ä¸Šä¸‹æ–‡ï¼Œç”¨äº S3 è¿æ¥æ£€æµ‹ç­‰ (è®¾ç½® 5ç§’ è¶…æ—¶é˜²æ­¢å¡æ­»)
	ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
	defer cancel()

	// 1. ç¡®å®šæœ¬åœ°ä»“åº“è·¯å¾„ (.tv)
	// é€»è¾‘ï¼šæ— è®ºæ•°æ®å­˜å“ªï¼Œæœ¬åœ°å¿…é¡»æœ‰ .tv ç”¨æ¥å­˜ index å’Œ HEAD
	// é»˜è®¤åœ¨å½“å‰ç›®å½•ä¸‹ï¼Œæˆ–è€…é€šè¿‡é…ç½®æŒ‡å®š
	workDir, err := os.Getwd()
	if err != nil {
		return nil, fmt.Errorf("failed to get working directory: %w", err)
	}
	localRepoPath := filepath.Join(workDir, ".tv")

	// æ£€æŸ¥æœ¬åœ°ä»“åº“æ˜¯å¦åˆå§‹åŒ–
	if _, err := os.Stat(localRepoPath); os.IsNotExist(err) {
		// è¿™é‡Œè¿”å›ç‰¹å®šé”™è¯¯ï¼Œæç¤ºç”¨æˆ·è¿è¡Œ init
		// æ³¨æ„ï¼šè¿™æ˜¯ä¸€ä¸ªâ€œè½¯é”™è¯¯â€ï¼Œä½†åœ¨ RunE é€»è¾‘é‡Œä¼šè¢«æ•è·
		return nil, fmt.Errorf("repository not found at %s (run 'tv init' first)", localRepoPath)
	}
	dbCfg := meta.Config{
		Host:     viper.GetString("database.host"),
		Port:     viper.GetInt("database.port"),
		User:     viper.GetString("database.user"),
		Password: viper.GetString("database.password"),
		DBName:   viper.GetString("database.dbname"),
		SSLMode:  viper.GetString("database.sslmode"),
	}

	conn, err := meta.NewDB(ctx, dbCfg)
	if err != nil {
		// [å…³é”®] æ‰“å°é»„è‰²çš„è­¦å‘Šï¼Œè€Œä¸æ˜¯çº¢è‰²çš„é”™è¯¯
		// è¿™é‡Œçš„åˆ¤æ–­é€»è¾‘å¯ä»¥æ›´ç»†è‡´ï¼šå¦‚æœé…ç½®æ˜æ˜¾æ˜¯ç©ºçš„ï¼Œç”šè‡³è¿è­¦å‘Šéƒ½ä¸æ‰“
		if dbCfg.User != "" {
			fmt.Printf("âš ï¸  Warning: Metadata DB not available (%v). Local commit/branching will be disabled.\n", err)
		}
	} else {
		metaDB = conn
		repository = meta.NewRepository(metaDB)
		refMgr = refs.NewManager(repository)
	}
	// 2. åˆå§‹åŒ–å­˜å‚¨åç«¯ (Storage Backend)
	store, err := initStore(ctx, localRepoPath)
	if err != nil {
		return nil, err
	}

	// 3. åˆå§‹åŒ–æœ¬åœ°çŠ¶æ€ç»„ä»¶ (Index & Refs)
	indexPath := filepath.Join(localRepoPath, "index.json")
	idx, err := index.NewIndex(indexPath)
	if err != nil {
		return nil, fmt.Errorf("failed to load index: %w", err)
	}

	return &App{
		Store:      store,
		Index:      idx,
		Refs:       refMgr,
		RepoPath:   localRepoPath,
		Repository: repository,
	}, nil
}

// -----------------------------------------------------------------------------
// Helper Methods (æœåŠ¡å®šä½å™¨æ¨¡å¼)
// -----------------------------------------------------------------------------

// GetExporter åˆ›å»ºå¹¶è¿”å›ä¸€ä¸ªæ–°çš„ Exporter å®ä¾‹
// ä¸ºä»€ä¹ˆä¸æŠŠå®ƒä½œä¸º App çš„å­—æ®µï¼Ÿå› ä¸º Exporter é€šå¸¸æ˜¯æ— çŠ¶æ€çš„ï¼Œ
// è€Œä¸”æ¯æ¬¡æ“ä½œå¯èƒ½æ¶‰åŠä¸åŒçš„ Context æˆ–é…ç½®å¾®è°ƒï¼ŒOn-demand åˆ›å»ºæ›´çµæ´»ä¸”å¼€é”€æä½ã€‚
func (a *App) GetExporter() *exporter.Exporter {
	return exporter.NewExporter(a.Store)
}

// initStore æ ¹æ®é…ç½®ç»„è£…å­˜å‚¨å±‚ (Base Store + Cache Layer)
func initStore(ctx context.Context, localRepoPath string) (storage.Store, error) {
	var baseStore storage.Store
	var err error

	// 1. åˆå§‹åŒ–åº•å±‚ç‰©ç†å­˜å‚¨ (Base Store)
	storageType := viper.GetString("storage.type")
	if storageType == "" {
		storageType = "disk"
	}

	fmt.Printf("ğŸ”Œ Storage Backend: %s\n", strings.ToUpper(storageType))

	switch storageType {
	case "disk":
		storePath := viper.GetString("storage.path")
		if storePath == "" {
			storePath = filepath.Join(localRepoPath, "objects")
		}
		baseStore, err = disk.NewAdapter(storePath)

	case "s3":
		cfg := s3.Config{
			Endpoint:        viper.GetString("storage.s3.endpoint"),
			Region:          viper.GetString("storage.s3.region"),
			Bucket:          viper.GetString("storage.s3.bucket"),
			AccessKeyID:     viper.GetString("storage.s3.access_key_id"),
			SecretAccessKey: viper.GetString("storage.s3.secret_access_key"),
		}
		if cfg.Bucket == "" {
			return nil, fmt.Errorf("storage.s3.bucket is required")
		}
		baseStore, err = s3.NewAdapter(ctx, cfg)

	default:
		return nil, fmt.Errorf("unsupported storage type: %s", storageType)
	}

	if err != nil {
		return nil, err
	}

	// 2. åˆå§‹åŒ–ç¼“å­˜å±‚ (Cache Layer Decorator)
	// æ£€æŸ¥é…ç½®æ˜¯å¦å¯ç”¨äº†ç¼“å­˜
	// TODO:é…ç½®ä½¿ç”¨Configç»“æ„ä½“è¯»å–æ›´æ¸…æ™°ï¼Œä½†ä¸ºäº†ç®€å•èµ·è§è¿™é‡Œç›´æ¥ç”¨ viper
	if viper.GetBool("storage.cache.enabled") {
		redisURL := viper.GetString("storage.cache.redis_url")
		if redisURL == "" {
			redisURL = "redis://localhost:6379/0"
		}

		ttl := viper.GetDuration("storage.cache.ttl")
		if ttl == 0 {
			ttl = 24 * time.Hour
		}

		fmt.Printf("ğŸš€ Cache Layer: Enabled (Redis @ %s)\n", redactPassword(redisURL))

		// Change: ä½¿ç”¨ Config ç»“æ„ä½“åˆå§‹åŒ–
		cacheCfg := cache.Config{
			RedisURL: redisURL,
			TTL:      ttl,
		}
		// ã€å…³é”®ã€‘ç”¨ CachedStore åŒ…è£¹ baseStore
		// æ­¤æ—¶è¿”å›çš„ store å¯¹è±¡ï¼Œå…¶ Has/Put æ–¹æ³•éƒ½ä¼šå…ˆç»è¿‡ Redis
		baseStore, err = cache.NewCachedStore(baseStore, cacheCfg)
		if err != nil {
			return nil, fmt.Errorf("failed to init redis cache: %w", err)
		}
	} else {
		fmt.Println("ğŸŒ Cache Layer: Disabled")
	}

	return baseStore, nil
}

// è¾…åŠ©å‡½æ•°ï¼šéšè— Redis URL ä¸­çš„å¯†ç ï¼Œé¿å…æ—¥å¿—æ³„éœ²
func redactPassword(url string) string {
	// ç®€å•å®ç°ï¼Œç”Ÿäº§ç¯å¢ƒå¯ä»¥ç”¨ url.Parse å¤„ç†
	// redis://user:password@host... -> redis://user:****@host...
	return url
}
