package exporter

import (
	"context"
	"fmt"
	"io"
	"os"
	"path/filepath"
	"text/tabwriter"
	"time"

	"tensorvault/pkg/core"
	"tensorvault/pkg/storage"
	"tensorvault/pkg/types"

	"golang.org/x/sync/errgroup"
)

const (
	RestoreWorkerCount = 16 // å¹¶å‘æ¢å¤çš„ Worker æ•°é‡
)

type Exporter struct {
	store storage.Store
}

func NewExporter(store storage.Store) *Exporter {
	return &Exporter{store: store}
}

// ExportFile æ™ºèƒ½å¯¼å‡ºæ–‡ä»¶
// å¦‚æœ writer æ”¯æŒ io.WriterAt (å¦‚ *os.File)ï¼Œåˆ™ä½¿ç”¨å¹¶å‘ä¸‹è½½ (Parallel Restore)
// å¦åˆ™ (å¦‚ os.Stdout)ï¼Œå›é€€åˆ°ä¸²è¡Œæµå¼ä¸‹è½½ (Serial Restore)
func (e *Exporter) ExportFile(ctx context.Context, hash types.Hash, writer io.Writer) error {
	// 1. è·å–å¹¶è§£æ FileNode
	nodeReader, err := e.store.Get(ctx, hash)
	if err != nil {
		return fmt.Errorf("failed to get filenode meta: %w", err)
	}
	defer nodeReader.Close()

	nodeBytes, err := io.ReadAll(nodeReader)
	if err != nil {
		return fmt.Errorf("failed to read filenode bytes: %w", err)
	}

	var fileNode core.FileNode
	if err := core.DecodeObject(nodeBytes, &fileNode); err != nil {
		return fmt.Errorf("failed to decode filenode: %w", err)
	}

	if fileNode.TypeVal != core.TypeFileNode {
		return fmt.Errorf("object is not a filenode, got: %s", fileNode.TypeVal)
	}

	// 2. ç­–ç•¥åˆ†å‘
	// æ£€æŸ¥ writer æ˜¯å¦æ”¯æŒâ€œéšæœºå†™å…¥â€ (WriteAt)
	if wAt, ok := writer.(io.WriterAt); ok {
		// ğŸš€ è·¯å¾„ A: å¹¶å‘æ¢å¤ (é€‚ç”¨äº Checkout åˆ°æœ¬åœ°æ–‡ä»¶)
		return e.exportFileConcurrent(ctx, &fileNode, wAt)
	}

	// ğŸŒ è·¯å¾„ B: ä¸²è¡Œæ¢å¤ (é€‚ç”¨äº Cat åˆ°æ ‡å‡†è¾“å‡º)
	return e.exportFileSerial(ctx, &fileNode, writer)
}

// exportFileSerial ä¼ ç»Ÿçš„ä¸²è¡Œæµå¼å®ç°
func (e *Exporter) exportFileSerial(ctx context.Context, fileNode *core.FileNode, writer io.Writer) error {
	for i, chunkLink := range fileNode.Chunks {
		err := func() error {
			rc, err := e.store.Get(ctx, chunkLink.Cid.Hash)
			if err != nil {
				return fmt.Errorf("failed to get chunk %d: %w", i, err)
			}
			defer rc.Close()

			if _, err := io.Copy(writer, rc); err != nil {
				return fmt.Errorf("failed to write chunk %d: %w", i, err)
			}
			return nil
		}()
		if err != nil {
			return err
		}
	}
	return nil
}

// restoreJob å¹¶å‘ä»»åŠ¡ç»“æ„
type restoreJob struct {
	hash   types.Hash
	offset int64 // å†™å…¥æ–‡ä»¶çš„ç»å¯¹åç§»é‡
	size   int   // é¢„æœŸå¤§å° (ç”¨äºæ ¡éªŒ)
}

// exportFileConcurrent å¹¶å‘ä¹±åºä¸‹è½½ + WriteAt
func (e *Exporter) exportFileConcurrent(ctx context.Context, fileNode *core.FileNode, writer io.WriterAt) error {
	g, ctx := errgroup.WithContext(ctx)
	jobsCh := make(chan restoreJob, RestoreWorkerCount*2)

	// ---------------------------------------------------------
	// Stage 1: Generator (è®¡ç®—åç§»é‡å¹¶åˆ†å‘)
	// ---------------------------------------------------------
	g.Go(func() error {
		defer close(jobsCh)
		var currentOffset int64 = 0

		// é¢„å…ˆè®¡ç®—æ¯ä¸ª Chunk åœ¨æ–‡ä»¶ä¸­çš„ç¡®åˆ‡ä½ç½®
		for _, chunk := range fileNode.Chunks {
			job := restoreJob{
				hash:   chunk.Cid.Hash,
				offset: currentOffset,
				size:   chunk.Size,
			}

			select {
			case jobsCh <- job:
			case <-ctx.Done():
				return ctx.Err()
			}

			// ç´¯åŠ åç§»é‡
			currentOffset += int64(chunk.Size)
		}
		return nil
	})

	// ---------------------------------------------------------
	// Stage 2: Workers (ä¸‹è½½å¹¶å†™å…¥)
	// ---------------------------------------------------------
	for range RestoreWorkerCount {
		g.Go(func() error {
			for job := range jobsCh {
				// 1. ä¸‹è½½ Chunk
				rc, err := e.store.Get(ctx, job.hash)
				if err != nil {
					return fmt.Errorf("download chunk %s failed: %w", job.hash, err)
				}

				// è¯»å–å…¨éƒ¨å†…å®¹åˆ°å†…å­˜
				// æ³¨æ„ï¼šChunk é€šå¸¸å¾ˆå° (8KB-64KB)ï¼Œå…¨éƒ¨è¯»å…¥å†…å­˜æ˜¯å®‰å…¨çš„
				data, err := io.ReadAll(rc)
				rc.Close() // å°½æ—©å…³é—­è¿æ¥
				if err != nil {
					return err
				}

				// ç®€å•æ ¡éªŒ
				if len(data) != job.size {
					return fmt.Errorf("integrity error: chunk %s size mismatch (want %d, got %d)", job.hash, job.size, len(data))
				}

				// 2. éšæœºå†™å…¥ (WriteAt)
				// è¿™æ˜¯å¹¶å‘æ¢å¤çš„æ ¸å¿ƒï¼šåªè¦çŸ¥é“ offsetï¼Œè°å…ˆä¸‹è½½å®Œè°å°±å…ˆå†™ï¼Œä¸éœ€è¦æ’é˜Ÿ
				if _, err := writer.WriteAt(data, job.offset); err != nil {
					return fmt.Errorf("writeAt failed at offset %d: %w", job.offset, err)
				}
			}
			return nil
		})
	}

	return g.Wait()
}

func (e *Exporter) PrintObject(ctx context.Context, hash types.Hash, writer io.Writer) error {
	// 1. è¯»å–åŸå§‹å­—èŠ‚
	reader, err := e.store.Get(ctx, hash)
	if err != nil {
		return err
	}
	defer reader.Close()

	data, err := io.ReadAll(reader)
	if err != nil {
		return err
	}

	// 2. å°è¯•é€šç”¨è§£ç ï¼Œæ¢æµ‹ç±»å‹
	// è¿™æ˜¯ä¸€ä¸ªå°çš„æ€§èƒ½å¼€é”€ï¼Œä½†ä¸ºäº† UX æ˜¯å€¼å¾—çš„
	var header struct {
		TypeVal core.ObjectType `cbor:"t"`
	}
	if err := core.DecodeObject(data, &header); err != nil {
		// å¦‚æœè§£ä¸å‡ºæ¥ï¼Œè¯´æ˜æ˜¯ Chunk (Raw Data)
		fmt.Fprintf(writer, "Type: Chunk (Raw Data)\nSize: %d bytes\n\n", len(data))
		// å¯¹äº Chunkï¼Œä¸ºäº†é˜²æ­¢ç»ˆç«¯ä¹±ç ï¼Œæˆ‘ä»¬åªæ‰“å°å‰ 100 å­—èŠ‚çš„ Hex
		// æˆ–è€…ä½ å¯ä»¥é€‰æ‹©ç›´æ¥è¾“å‡ºå†…å®¹ï¼Œè§†éœ€æ±‚è€Œå®š
		fmt.Fprintf(writer, "(Raw binary data not shown, use 'tv cat ... > file' to save)\n")
		return nil
	}

	// 3. æ ¹æ®ç±»å‹åˆ†å‘å¤„ç†
	switch header.TypeVal {
	case core.TypeCommit:
		return printCommit(data, writer)
	case core.TypeTree:
		return printTree(data, writer)
	case core.TypeFileNode:
		// å¦‚æœæ˜¯æ–‡ä»¶èŠ‚ç‚¹ï¼Œè¿˜æ˜¯èµ°åŸæ¥çš„â€œè¿˜åŸæ–‡ä»¶â€é€»è¾‘å—ï¼Ÿ
		// ä¸ºäº† cat å‘½ä»¤çš„ä¸€è‡´æ€§ï¼Œå¦‚æœæ˜¯ FileNodeï¼Œæˆ‘ä»¬åº”è¯¥è¾“å‡ºå®ƒçš„å…ƒæ•°æ®ä¿¡æ¯
		// å¦‚æœç”¨æˆ·æƒ³ä¸‹è½½æ–‡ä»¶ï¼Œåº”è¯¥ç”¨ `tv checkout` æˆ–è€… `tv cat --raw`
		// è¿™é‡Œæˆ‘ä»¬å…ˆå±•ç¤ºå…ƒæ•°æ®
		return printFileNode(data, writer)
	default:
		return fmt.Errorf("unknown object type: %s", header.TypeVal)
	}
}

// --- è¾…åŠ©æ‰“å°å‡½æ•° ---

func printCommit(data []byte, w io.Writer) error {
	var c core.Commit
	if err := core.DecodeObject(data, &c); err != nil {
		return err
	}
	fmt.Fprintf(w, "Type:    Commit\n")
	fmt.Fprintf(w, "Tree:    %s\n", c.TreeCid.Hash)
	for _, p := range c.Parents {
		fmt.Fprintf(w, "Parent:  %s\n", p.Hash)
	}
	fmt.Fprintf(w, "Author:  %s\n", c.Author)
	fmt.Fprintf(w, "Time:    %s\n", time.Unix(c.Timestamp, 0).Format(time.RFC3339))
	fmt.Fprintf(w, "\n%s\n", c.Message)
	return nil
}

func printTree(data []byte, w io.Writer) error {
	var t core.Tree
	if err := core.DecodeObject(data, &t); err != nil {
		return err
	}
	fmt.Fprintf(w, "Type: Tree\n\n")

	// ä½¿ç”¨ tabwriter å¯¹é½è¾“å‡º (åƒ git ls-tree)
	tw := tabwriter.NewWriter(w, 0, 0, 3, ' ', 0)
	for _, entry := range t.Entries {
		fmt.Fprintf(tw, "%s\t%s\t%s\t%s\n", entry.Type, entry.Cid.Hash[:8], entry.Name, fmtSize(entry.Size))
	}
	tw.Flush()
	return nil
}

func printFileNode(data []byte, w io.Writer) error {
	var f core.FileNode
	if err := core.DecodeObject(data, &f); err != nil {
		return err
	}
	fmt.Fprintf(w, "Type:      FileNode (ADL)\n")
	fmt.Fprintf(w, "TotalSize: %d bytes\n", f.TotalSize)
	fmt.Fprintf(w, "Chunks:    %d\n", len(f.Chunks))
	return nil
}

func fmtSize(s int64) string {
	if s == 0 {
		return "-"
	}
	return fmt.Sprintf("%d", s)
}

type RestoreCallback func(path string, hash types.Hash, size int64)

// RestoreTree é€’å½’åœ°å°† Merkle Tree è¿˜åŸåˆ°ç›®æ ‡ç›®å½•
func (e *Exporter) RestoreTree(ctx context.Context, treeHash types.Hash, targetDir string, onRestore RestoreCallback) error {
	// 1. è·å– Tree å¯¹è±¡
	reader, err := e.store.Get(ctx, treeHash)
	if err != nil {
		return fmt.Errorf("failed to get tree %s: %w", treeHash, err)
	}

	treeBytes, err := io.ReadAll(reader)
	reader.Close()
	if err != nil {
		return err
	}

	var tree core.Tree
	if err := core.DecodeObject(treeBytes, &tree); err != nil {
		return fmt.Errorf("failed to decode tree: %w", err)
	}

	// 2. éå† Tree Entries
	for _, entry := range tree.Entries {
		fullPath := filepath.Join(targetDir, entry.Name)

		if entry.Type == core.EntryDir {
			// A. å¤„ç†ç›®å½•ï¼šåˆ›å»ºç›®å½• -> é€’å½’
			if err := os.MkdirAll(fullPath, 0755); err != nil {
				return fmt.Errorf("failed to create dir %s: %w", fullPath, err)
			}
			// é€’å½’è°ƒç”¨
			if err := e.RestoreTree(ctx, entry.Cid.Hash, fullPath, onRestore); err != nil {
				return err
			}
		} else {
			// B. å¤„ç†æ–‡ä»¶ï¼šå¯¼å‡ºæ–‡ä»¶ -> è§¦å‘å›è°ƒ
			// åˆ›å»º/è¦†ç›–æ–‡ä»¶
			file, err := os.Create(fullPath)
			if err != nil {
				return fmt.Errorf("failed to create file %s: %w", fullPath, err)
			}

			// å¤ç”¨å·²æœ‰çš„ ExportFile é€»è¾‘ (æµå¼å†™å…¥)
			if err := e.ExportFile(ctx, entry.Cid.Hash, file); err != nil {
				file.Close()
				return err
			}
			file.Close()

			// è§¦å‘å›è°ƒ (é€šçŸ¥ä¸Šå±‚æ›´æ–° Index)
			if onRestore != nil {
				onRestore(fullPath, entry.Cid.Hash, entry.Size)
			}
		}
	}

	return nil
}
